{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41ce665a-2e7b-4cf2-8dbb-83c95f4a6177",
   "metadata": {},
   "source": [
    "## Q1. What is multiprocessing in python? Why is it useful?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1201890-4250-407b-add4-38b3cf312991",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d12d61-b1dd-4385-b73c-9b8380a9d38b",
   "metadata": {},
   "source": [
    "Multiprocessing in Python refers to the execution of multiple processes concurrently in order to achieve parallelism and utilize multiple CPU cores effectively. Unlike multithreading, where multiple threads share the same memory space within a single process, multiprocessing involves running multiple independent processes, each with its own memory space, interpreter, and resources.\n",
    "\n",
    "Python's Global Interpreter Lock (GIL) limits the true parallel execution of threads in a single process, making it challenging to achieve true parallelism for CPU-bound tasks using the threading module. Multiprocessing overcomes this limitation by creating separate processes, each with its own Python interpreter and memory, allowing them to run truly concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960e223a-9afe-4b66-9028-b5e6e7e0df7a",
   "metadata": {},
   "source": [
    "Multiprocessing is useful for several reasons:\n",
    "\n",
    "1. Parallelism for CPU-Bound Tasks: Multiprocessing enables parallel execution of CPU-bound tasks, which can lead to significant performance improvements. Each process can utilize a separate CPU core, leading to true parallel computation.\n",
    "\n",
    "2. GIL Bypass: Since each process in multiprocessing has its own interpreter and memory space, the GIL limitation is not applicable. This makes multiprocessing suitable for CPU-bound tasks that can't take full advantage of multithreading.\n",
    "\n",
    "3. Scalability: Multiprocessing allows you to fully utilize the available CPU cores, making your program more scalable and capable of handling computationally intensive tasks efficiently.\n",
    "\n",
    "4. Isolation: Processes in multiprocessing are isolated from each other, which means that if one process crashes, it doesn't affect the others. This can lead to increased stability and reliability.\n",
    "\n",
    "5. Distributed Computing: Multiprocessing can be used for distributed computing across multiple machines, allowing you to scale your computations even further.\n",
    "\n",
    "6. Resource Sharing: While processes have their own memory space, you can still share data between processes using various inter-process communication mechanisms, like pipes, queues, and shared memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01999180-21d2-4162-8752-06616f4bed06",
   "metadata": {},
   "source": [
    "## Q2. What are the differences between multiprocessing and multithreading?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64212aeb-8d16-4184-a362-9120e517a248",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88255edd-c879-43ab-926d-d97ce4550a14",
   "metadata": {},
   "source": [
    "Multiprocessing and multithreading are both techniques for achieving concurrency in programs, but they have distinct differences in terms of their execution model, resource sharing, and performance characteristics. Here's a comparison of multiprocessing and multithreading:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d60c38-2188-4659-b6ca-a056139de6ba",
   "metadata": {},
   "source": [
    "1. In multiprocessing, multiple independent processes are created, each with its own memory space and Python interpreter. Processes do not share memory, and communication between processes is typically achieved through inter-process communication mechanisms like pipes, queues, and shared memory. On the other hand in multithreading, multiple threads exist within a single process, sharing the same memory space and resources. Threads are lighter-weight than processes and have less overhead in terms of memory consumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e74fb-39da-4237-84c4-54de0d70188b",
   "metadata": {},
   "source": [
    "2. Multiprocessing provides true parallelism since each process can run on a separate CPU core, fully utilizing the available hardware resources. It is suitable for CPU-bound tasks. On the other hand, Due to the Global Interpreter Lock (GIL) in Python, multithreading does not provide true parallelism for CPU-bound tasks. Only one thread can execute Python bytecode at a time, which limits the utilization of multiple CPU cores. However, multithreading is effective for IO-bound tasks where threads spend time waiting for external resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0389e986-7f82-443b-9b49-fb3cf2caa7b7",
   "metadata": {},
   "source": [
    "3. In multi-processing processes are isolated from each other, which means that if one process crashes, it does not affect the others. This can lead to increased stability and reliability. On the other hand, in multi-threading threads within the same process share the same memory space. If one thread crashes or experiences issues like memory corruption, it can affect the entire process, leading to potential stability problems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5544005-ea1e-44af-ba43-dcc0fd1970ed",
   "metadata": {},
   "source": [
    "4. Processes communicate through explicit inter-process communication mechanisms like pipes, queues, and shared memory. Synchronization between processes requires the use of these mechanisms. On the other hand, threads within the same process can communicate directly through shared data structures. However, proper synchronization mechanisms (like locks, semaphores, and conditions) are required to avoid race conditions and ensure thread safety."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a1687-dc1b-4dc7-974e-fae0caf1761f",
   "metadata": {},
   "source": [
    "5.  Processes have a higher memory overhead due to the need for separate memory spaces and Python interpreters. On the other hand, threads have lower memory overhead as they share the same memory space and interpreter within a process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b041fd79-b002-4d67-b56a-73382d2cc6b6",
   "metadata": {},
   "source": [
    "6. Best suited for CPU-bound tasks that can take advantage of true parallelism, distributed computing, and scenarios where isolation and stability are critical. On the other hand,  Effective for IO-bound tasks that involve waiting for external resources, tasks involving GUI responsiveness, and situations where resource sharing within a process is required."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ea00e-856b-4d02-b53f-c0812d26a877",
   "metadata": {},
   "source": [
    "## Q3. Write a python code to create a process using the multiprocessing module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479df0bb-2774-47d3-bafc-fbfa14b53de6",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697c26ae-34e5-467d-9224-3c35b79cd05c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ram\n",
      "hari\n",
      "kamal\n",
      "bimal\n",
      "madhu\n",
      "xyz\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def producer(q):\n",
    "    for i in [\"ram\" , \"hari\" , \"kamal\" , \"bimal\" ,\"madhu\"] : \n",
    "        q.put(i)# putting data in queue\n",
    "    \n",
    "def consume(q) : \n",
    "    while True :\n",
    "        item = q.get() # extracting data from queue\n",
    "        if item is None :\n",
    "            break \n",
    "        print(item)\n",
    "        \n",
    "if __name__ == '__main__':\n",
    "    queue = multiprocessing.Queue() # Queue is being used to share memory between different processes\n",
    "    m1 = multiprocessing.Process(target=producer , args= (queue,))\n",
    "    m2 = multiprocessing.Process(target=consume ,args=(queue,) )\n",
    "    m1.start()\n",
    "    m2.start()\n",
    "    queue.put(\"xyz\")\n",
    "    m1.join()\n",
    "    m2.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be7ec46-7e38-4216-a462-b6b217b05174",
   "metadata": {},
   "source": [
    "## Q4. What is a multiprocessing pool in python? Why is it used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a80476-7a70-47d8-b59a-c28cefdb2658",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5385ee03-e505-4535-844e-08496b7e8a56",
   "metadata": {},
   "source": [
    "A multiprocessing pool in Python, specifically the multiprocessing.Pool class, is a convenient way to parallelize the execution of a function across multiple processes. It provides a high-level interface for creating a pool of worker processes that can execute a given function in parallel, distributing the workload efficiently.\n",
    "\n",
    "The primary purpose of a multiprocessing pool is to enable parallel processing of tasks, particularly in scenarios where you have a set of tasks to be executed concurrently. Instead of managing individual processes yourself, a pool abstracts the process management and allows you to focus on the tasks you want to parallelize.\n",
    "\n",
    "Here's how a multiprocessing pool is used and its benefits:\n",
    "\n",
    "Usage of multiprocessing.Pool:\n",
    "\n",
    "1. Import the multiprocessing module.\n",
    "2. Create an instance of multiprocessing.Pool with a specified number of worker processes.\n",
    "3.  Use the map(), imap(), or other methods of the pool to distribute tasks to the worker processes.\n",
    "4.  The tasks are executed in parallel across the worker processes, and the results are collected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dddf1638-6572-4539-9b0c-6b7c07091085",
   "metadata": {},
   "source": [
    "Reasons for using a Multiprocessing Pool:\n",
    "\n",
    "1. Simplicity: Using a pool abstracts away the complexity of managing individual processes, allowing you to focus on the tasks themselves.\n",
    "\n",
    "2. Efficiency: Pools reuse the existing processes, minimizing the overhead of creating and destroying processes for each task. This leads to better performance compared to creating processes individually.\n",
    "\n",
    "3. Parallelism: The pool distributes the tasks across multiple processes, achieving parallel execution and utilizing multiple CPU cores.\n",
    "\n",
    "4. Task-Level Granularity: Pools are useful when you have a set of tasks that can be executed independently. They work well for tasks that are not highly dependent on each other.\n",
    "\n",
    "5. Controlled Resource Usage: You can control the number of worker processes in the pool, which allows you to manage the level of parallelism based on the available hardware resources."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09e985c6-afcb-4870-8ec5-70cdcf9cfe9f",
   "metadata": {},
   "source": [
    "## Q5. How can we create a pool of worker processes in python using the multiprocessing module?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d07b52-7625-4275-b7e7-e605459f8ba1",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bc8c40-8e57-47da-bed2-402a7562dcb1",
   "metadata": {},
   "source": [
    "    Import the multiprocessing module:\n",
    "\n",
    "1. Start by importing the multiprocessing module, which provides classes and functions for working with processes and pools.\n",
    "\n",
    "2. Create a Pool: Use the Pool class to create a pool of worker processes. You can specify the number of worker processes you want in the pool using the processes parameter.\n",
    "\n",
    "3. Distribute Tasks: Once the pool is created, you can use its methods to distribute tasks to the worker processes. The most common method for distributing tasks is map(), which applies a given function to a list of inputs in parallel.\n",
    "4. Close and Join: After distributing tasks, you should close the pool to prevent any more tasks from being submitted. Then, use the join() method to wait for all worker processes to complete their tasks and terminate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3dbfd5d-8280-431b-9ad2-a6e86fcf097d",
   "metadata": {},
   "source": [
    "## Q6. Write a python program to create 4 processes, each process should print a different number using the multiprocessing module in python."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9756189b-6f7c-4d17-ad8e-971c844fb063",
   "metadata": {},
   "source": [
    "## Ans:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f63353c-7563-4d99-9e07-e08da16a8c40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process Process-3 Processprints:  ProcessProcess-41  \n",
      "Process-5prints:  Processprints:2 \n",
      " Process-63 \n",
      "prints: 4\n",
      "All processes have completed.\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "# Function to print a number\n",
    "def print_number(number):\n",
    "    print(\"Process\", multiprocessing.current_process().name, \"prints:\", number)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create a list of numbers\n",
    "    numbers = [1, 2, 3, 4]\n",
    "\n",
    "    # Create a list to hold process objects\n",
    "    processes = []\n",
    "\n",
    "    # Create and start 4 processes\n",
    "    for num in numbers:\n",
    "        process = multiprocessing.Process(target=print_number, args=(num,))\n",
    "        processes.append(process)\n",
    "        process.start()\n",
    "\n",
    "    # Wait for all processes to complete\n",
    "    for process in processes:\n",
    "        process.join()\n",
    "\n",
    "    print(\"All processes have completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faee9032-66d0-48f9-906b-57a264588a54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
